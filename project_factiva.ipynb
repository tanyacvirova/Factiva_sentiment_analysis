{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install the necessary libraries and modules\n",
    "\n",
    "# news_extract to extract news articles from Factiva to data frame\n",
    "!pip install news_extract\n",
    "\n",
    "# wordcloud to create wordcloud from text articles and headlines\n",
    "!pip install wordcloud\n",
    "\n",
    "# pycountry to create a list of countries\n",
    "!pip install pycountry \n",
    "\n",
    "# vaderSentiment to sentiment analysis with Vader library\n",
    "!pip install vaderSentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import news_extract as ne\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import ipywidgets as widgets\n",
    "import pycountry\n",
    "import seaborn as sns\n",
    "from afinn import Afinn\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# module news_extract extracts articles and associated metadata from pre-exported output files\n",
    "# all pre-exported files are stored in the folder 'Factiva_new'\n",
    "files = os.listdir('C:/Users/cvirova-t/Factiva_new')\n",
    "\n",
    "full_df = pd.DataFrame()\n",
    "\n",
    "# in a loop for each file in the folder 'Factiva_new', create a list, \n",
    "#then turn it into a DataFrame and add to the general DataFrame with all files\n",
    "for f in files:\n",
    "    fc_data = ne.factiva_extract(\"C:/Users/cvirova-t/Factiva_new/\" + f)\n",
    "    df = pd.DataFrame(fc_data)\n",
    "    full_df = pd.concat([full_df, df], sort = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select columns from the general data frame to work with \n",
    "# 'HD' is headings, 'TXT' is texts of articles, 'PD' is publication date,\n",
    "# 'SN' is publidhers, 'NS' is topics, 'RE' is countries\n",
    "work_df = full_df[['HD', 'PD', 'SN', 'TXT', 'NS', 'RE']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a widget so that the user can select a year: 2019 or 2020\n",
    "# and the type of text: texts of articles or headings\n",
    "choose_year = widgets.Dropdown(options = ['2019', '2020'], \n",
    "                          value = '2019', \n",
    "                          description = 'Year: ', \n",
    "                          disabled = False)\n",
    "choose_text = widgets.Dropdown(options = [('Texts', 'TXT'), ('Headings', 'HD')], \n",
    "                          value = 'TXT', \n",
    "                          description = 'Type: ', \n",
    "                          disabled = False)\n",
    "display(choose_year)\n",
    "display(choose_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of all texts for wordcloud module\n",
    "# use the values received from the user to sort the columns\n",
    "test_df = work_df.copy()\n",
    "test_df.dropna(inplace = True)\n",
    "get_year = work_df[work_df['PD'].str.contains(choose_year.value)]\n",
    "all_texts = \" \".join(get_year[choose_text.value].values)\n",
    "all_texts = all_texts.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of positive words \n",
    "df_positive = pd.read_table('C:/Users/cvirova-t/positive-words.txt') \n",
    "clear_positive = df_positive.iloc[34:, 0] \n",
    "positive_words = list(clear_positive.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of negative words\n",
    "df_negative = pd.read_table('C:/Users/cvirova-t/negative-words.txt') \n",
    "clear_negative = df_negative.iloc[35:, 0] \n",
    "negative_words = list(clear_negative.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOPWORDS.update({'millennial', 'millennials', 'generation', \n",
    "                  'gen', 'us', 'per cent', 'per', 'cent', \n",
    "                  'age', 'year', 'make', 'percent', 'according', \n",
    "                  'one', 'said', 'say', 'among', 'three',\n",
    "                 'gen Y', 'generation Y', 'will', 'two'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_color_func(word, font_size, position, orientation, random_state = None,\n",
    "                    **kwargs):\n",
    "    \"\"\"\n",
    "    Parameter: word is the word in wordCloud.\n",
    "    Returns the color for word in wordCloud.\n",
    "    \"\"\"\n",
    "    positive = positive_words\n",
    "    negative = negative_words\n",
    "    if word in positive:\n",
    "        col = 'forestgreen'\n",
    "    elif word in negative:\n",
    "        col = 'crimson'\n",
    "    else:\n",
    "        col = 'silver'\n",
    "    return col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_color_func2(word, font_size, position, orientation, random_state = None,\n",
    "                    **kwargs):\n",
    "    if afinn.score(word) > 0:\n",
    "        col = 'forestgreen'\n",
    "    elif afinn.score(word) < 0:\n",
    "        col = 'crimson'\n",
    "    else:\n",
    "        col = 'silver'\n",
    "    return col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a wordcloud with 50 most popular words of all articles\n",
    "wordcloud = WordCloud(background_color = 'white', \n",
    "                     max_words = 50,\n",
    "                     stopwords = STOPWORDS,\n",
    "                     width = 2000,\n",
    "                     height = 1200,\n",
    "                     font_step = 1).generate(all_texts)\n",
    "\n",
    "# customize the word output\n",
    "plt.figure(figsize = [15, 15])\n",
    "default_colors = wordcloud.to_array()\n",
    "plt.imshow(wordcloud.recolor(color_func = my_color_func, random_state = 3),\n",
    "           interpolation = 'bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the picture to png file\n",
    "wordcloud.to_file(f'wordcoud_{choose_text.value}_{choose_year.value}.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantitative analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of unique topics\n",
    "\n",
    "# create a list of unique values from dataframe column 'NS'\n",
    "NS = work_df[['NS']].copy()\n",
    "NS.dropna(inplace = True)\n",
    "NS_list = list(NS['NS'].unique())\n",
    "\n",
    "# separate topics for each article from each other \n",
    "NS_split = []\n",
    "for i in NS_list: \n",
    "    NS_split.extend(i.split('|'))\n",
    "NS_dict = {k:v for k,v in (x.split(':') for x in NS_split)}\n",
    "\n",
    "# clear values, add unique ones to the empty list\n",
    "topics = []\n",
    "for i in NS_dict.values():\n",
    "    i = i.replace('\\n', ' ').strip()\n",
    "    if i not in topics:\n",
    "        topics.append(i)\n",
    "topics.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of unique publishers\n",
    "publishers = work_df['SN'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of unique countries\n",
    "countries = []\n",
    "for i in list(pycountry.countries):\n",
    "    countries.append(i.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of unique companies\n",
    "with open('C:/Users/cvirova-t/comps.csv', 'r') as fileObj:\n",
    "    contents = fileObj.read().replace('\\n', ',')\n",
    "contents\n",
    "comps = contents.split(',')\n",
    "comps_clean = []\n",
    "for comp in comps:\n",
    "    clean = comp.strip()\n",
    "    comps_clean.append(clean)\n",
    "comps_clean.append('Netflix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_uniques(dataframe, column_to_find, column_year, \n",
    "                  list_of_uniques, year, total_number):\n",
    "    \"\"\"\n",
    "    Parameters: dataframe is the name of dataframe to work with,\n",
    "                column_to_find is the name of the column where to find unique values,\n",
    "                column_year is the name of the column with publication date, \n",
    "                list_of_uniques is the name of list with unique values, \n",
    "                year is the string,\n",
    "                total_number is the number, min value.\n",
    "    Returns a new dataframe.\n",
    "    \"\"\"\n",
    "    test_array = np.zeros(len(list_of_uniques), dtype = np.int64)\n",
    "    get_year = dataframe[dataframe[column_year].str.contains(year)]\n",
    "    \n",
    "    for el in get_year[column_to_find]:\n",
    "        if pd.isnull(el):\n",
    "            continue\n",
    "        for index in range(len(list_of_uniques)):\n",
    "            if list_of_uniques[index] in el:\n",
    "                test_array[index] += 1\n",
    "                \n",
    "    test_df = pd.DataFrame(list(zip(list_of_uniques, test_array)))\n",
    "    test_df = test_df[test_df[1] > total_number] \n",
    "    test_df = test_df.sort_values(by = [1], ascending = False)\n",
    "    \n",
    "    return test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Barplot(dataframe, column_for_x, column_for_y, \n",
    "           name_x_axis, name_y_axis):\n",
    "    \"\"\"\n",
    "    Parameters: dataframe is the name of dataframe to work with,\n",
    "                column_for_x is the name of the column to be displayed on the x axis, \n",
    "                column_for_y is the name of the column to be displayed on the y axis,\n",
    "                name_x_axis is the name of the x axis,\n",
    "                name_y_axis is the name of the y axis.\n",
    "    Returns a barplot.\n",
    "    \"\"\"\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    x = dataframe[column_for_x]\n",
    "    y = dataframe[column_for_y]\n",
    "    \n",
    "    plt.figure(figsize = (15, 5))\n",
    "    plt.xticks(rotation = 90)\n",
    "    graph = sns.barplot(x, y, color = 'forestgreen')\n",
    "    \n",
    "    plt.ylabel(name_y_axis)\n",
    "    plt.xlabel(name_x_axis)\n",
    "    \n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a widget so that the user can select a year: 2019 or 2020\n",
    "# and the category: publishers, topics or countries\n",
    "choose_year2 = widgets.Dropdown(options = ['2019', '2020'], \n",
    "                          value = '2019', \n",
    "                          description = 'Year: ', \n",
    "                          disabled = False)\n",
    "choose_category = widgets.Dropdown(options = ['Publishers', 'Topics', 'Countries'], \n",
    "                          value = 'Publishers', \n",
    "                          description = 'Category: ', \n",
    "                          disabled = False)\n",
    "display(choose_year2)\n",
    "display(choose_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if choose_year2.value == '2019':\n",
    "    if choose_category.value == 'Publishers':\n",
    "        publishers_values_2019 = count_uniques(work_df, 'SN', 'PD', publishers, '2019', 30)\n",
    "        publishers_values_2019.drop(59, inplace = True)\n",
    "        sns_plot = Barplot(publishers_values_2019, 0, 1, 'Publishers', 'Number of articles')\n",
    "    elif choose_category.value == 'Topics':\n",
    "        topics_values_2019 = count_uniques(work_df, 'NS', 'PD', topics, '2019', 70)\n",
    "        #topics_values_2019.drop([59, 126, 34, 33], inplace = True)\n",
    "        sns_plot = Barplot(topics_values_2019, 0, 1, 'Topics', 'Number of articles')\n",
    "    elif choose_category.value == 'Countries':\n",
    "        countries_values_2019 = count_uniques(work_df, 'RE', 'PD', countries, '2019', 50)\n",
    "        sns_plot = Barplot(countries_values_2019, 0, 1, 'Countries', 'Number of articles')\n",
    "\n",
    "elif choose_year2.value == '2020':\n",
    "    if choose_category.value == 'Publishers':\n",
    "        publishers_values_2020 = count_uniques(work_df, 'SN', 'PD', publishers, '2020', 30)\n",
    "        publishers_values_2020.drop(59, inplace = True)\n",
    "        sns_plot = Barplot(publishers_values_2020, 0, 1, 'Publishers', 'Number of articles')\n",
    "    elif choose_category.value == 'Topics':\n",
    "        topics_values_2020 = count_uniques(work_df, 'NS', 'PD', topics, '2020', 70)\n",
    "        #topics_values_2020.drop([59, 126, 34], inplace = True)\n",
    "        sns_plot = Barplot(topics_values_2020, 0, 1, 'Topics', 'Number of articles')\n",
    "    elif choose_category.value == 'Countries':\n",
    "        countries_values_2020 = count_uniques(work_df, 'RE', 'PD', countries, '2020', 50)\n",
    "        sns_plot = Barplot(countries_values_2020, 0, 1, 'Countries', 'Number of articles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the barplot to png file\n",
    "fig = sns_plot.get_figure()\n",
    "fig.savefig(f'barplot_{choose_category.value}_{choose_year2.value}.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose language for Afinn library \n",
    "afinn = Afinn(language='en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying the function for news texts in 'TXT'\n",
    "work_df['AF_TXT'] = work_df['TXT'].apply(afinn.score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create hist plots to visualize Afinn scores\n",
    "gist_df = work_df[(work_df['PD'].str.contains('2020')) & (work_df['NS'].str.contains('Health'))]\n",
    "bins = np.arange(-20, 35, 5)\n",
    "n, bins, patches = plt.hist(gist_df['AF_TXT'], bins = bins, histtype = 'bar', color = 'black')\n",
    "sns.set(style = \"darkgrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up the y axis to reflect % of all news\n",
    "centers = np.zeros_like(n)\n",
    "for ind in range(len(bins) - 1):\n",
    "    centers[ind] = np.mean([bins[ind], bins[ind + 1]])\n",
    "plt.bar(centers, n / sum(n), width = 4.8, color = 'black')\n",
    "plt.ylim(top = 0.5)\n",
    "plt.savefig('graph_Y_A_HLT_2020.png', dpi = 300, format = 'png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# % of positive and neutral news in all news\n",
    "sum(n[centers >= 0])/sum(n) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new DataFrame with Vader library scores\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "exp_df = work_df[(work_df['PD'].str.contains('2020')) & (work_df['NS'].str.contains('Health'))]\n",
    "sentiment = exp_df['TXT'].apply(analyzer.polarity_scores)\n",
    "sentiment_df = pd.DataFrame(sentiment.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create hist plots to visualize Vader scores\n",
    "bins = np.arange(-1, 1.25, 0.25)\n",
    "n, bins, patches = plt.hist(sentiment_df['compound'], bins = bins, histtype = 'bar', color = 'black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up the y axis to reflect % of all news\n",
    "centers = np.zeros_like(n)\n",
    "for ind in range(len(bins) - 1):\n",
    "    centers[ind] = np.mean([bins[ind], bins[ind + 1]])\n",
    "plt.bar(centers, n / sum(n), width = 0.24, color = 'black')\n",
    "plt.ylim([0, 0.5])\n",
    "plt.savefig('graph_VD_Y_HLT_2020.png', dpi = 300, format = 'png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# % of positive and neutral news in all news\n",
    "sum(n[centers>=0])/sum(n)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
